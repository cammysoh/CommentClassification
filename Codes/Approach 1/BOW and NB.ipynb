{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify import apply_features\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "  \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display setting to show more characters\n",
    "pd.options.display.max_colwidth = 999\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/User/Downloads/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50960, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>clean</th>\n",
       "      <th>cleaned_comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2f52adcf5a111cd3</td>\n",
       "      <td>That is about it for for now. Primarily, I worked on citations (either adding or updating) and related format or reconciling previous contributions into a more NPOV (or BPOV) format. Feel free to smoke it over.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>primarily work citations either add update relate format reconcile previous contributions npov bpov format feel free smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>819b3339c747286f</td>\n",
       "      <td>\"\\n I wasn't aware that peer-reviewed studies with minimal to no methodological flaws (you know.. what the page i linked is citing) constitute \"\"biased sources\"\".  *restrains self from becoming extremely sarcastic*  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>aware peerreviewed study minimal methodological flaw know page link cite constitute bias source restrain self become extremely sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b66e5fffbd70f8fe</td>\n",
       "      <td>\"\\nIt's fine to edit for personal gain so long as you're editing according to basic policies. Contributing to Wikipedia is a hobby for most people, and there is an endless number of motivations for getting involved. â''''''Â |Â Talk \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>fine edit personal gain long edit accord basic policies contribute wikipedia hobby people endless number motivations get involve talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fd7f2ec6efe0315d</td>\n",
       "      <td>I did not add these words to the PLANS website. I have no contact with PLANS. PLANS is a skeptic site and the language you quote is strong but not offensive to a most people. PLANS is cited as evidence of a balancing point of view,  Very little of its content is present in the Wikipedia article.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>add word plan website contact plan plan skeptic site language quote strong offensive people plan cite evidence balance point view little content present wikipedia article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f78b624060552c1a</td>\n",
       "      <td>\"\\n\\n List of recent changes \\n\\nRequested by Sarge Baldy, even though they've already been discussed extensively.\\n\\n We don't need minutia about Cromwell in the intro.\\n This article is about the political meaning of anarchism \"\"the belief that forms of rulership are undesireable, and should be abolished.\"\"\\n We don't need the gobbletygook about \"\"degrees of commonality and conflict.\"\"\\n Please don't hide the fact that Proudhon was anti-communist.\\n Proudhon details should go in the Proudhon article, not here.\\n Anarchist \"\"schools\"\" should precede all the sundry issue-oriented sects.\\n Bullshit about misc. non-anarchist leftie movements don't belong in the [i]anarchism without adjectives[/i] paragraph.\\n Ancap books should not be censored.\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>list recent change request sarge baldy even though already discuss extensively need minutia cromwell intro article political mean anarchism belief form rulership undesireable abolish need gobbletygook degrees commonality conflict please hide fact proudhon anticommunist proudhon detail go proudhon article anarchist school precede sundry issueoriented sects bullshit misc nonanarchist leftie movements belong anarchism without adjectives i paragraph ancap book censor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  \\\n",
       "0  2f52adcf5a111cd3   \n",
       "1  819b3339c747286f   \n",
       "2  b66e5fffbd70f8fe   \n",
       "3  fd7f2ec6efe0315d   \n",
       "4  f78b624060552c1a   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        comment_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 That is about it for for now. Primarily, I worked on citations (either adding or updating) and related format or reconciling previous contributions into a more NPOV (or BPOV) format. Feel free to smoke it over.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \"\\n I wasn't aware that peer-reviewed studies with minimal to no methodological flaws (you know.. what the page i linked is citing) constitute \"\"biased sources\"\".  *restrains self from becoming extremely sarcastic*  \"   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \"\\nIt's fine to edit for personal gain so long as you're editing according to basic policies. Contributing to Wikipedia is a hobby for most people, and there is an endless number of motivations for getting involved. â''''''Â |Â Talk \"   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                           I did not add these words to the PLANS website. I have no contact with PLANS. PLANS is a skeptic site and the language you quote is strong but not offensive to a most people. PLANS is cited as evidence of a balancing point of view,  Very little of its content is present in the Wikipedia article.   \n",
       "4  \"\\n\\n List of recent changes \\n\\nRequested by Sarge Baldy, even though they've already been discussed extensively.\\n\\n We don't need minutia about Cromwell in the intro.\\n This article is about the political meaning of anarchism \"\"the belief that forms of rulership are undesireable, and should be abolished.\"\"\\n We don't need the gobbletygook about \"\"degrees of commonality and conflict.\"\"\\n Please don't hide the fact that Proudhon was anti-communist.\\n Proudhon details should go in the Proudhon article, not here.\\n Anarchist \"\"schools\"\" should precede all the sundry issue-oriented sects.\\n Bullshit about misc. non-anarchist leftie movements don't belong in the [i]anarchism without adjectives[/i] paragraph.\\n Ancap books should not be censored.\"   \n",
       "\n",
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  clean  \\\n",
       "0      0             0        0       0       0              0      1   \n",
       "1      0             0        0       0       0              0      1   \n",
       "2      0             0        0       0       0              0      1   \n",
       "3      0             0        0       0       0              0      1   \n",
       "4      0             0        0       0       0              0      1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                  cleaned_comment_text  \n",
       "0                                                                                                                                                                                                                                                                                                                                                           primarily work citations either add update relate format reconcile previous contributions npov bpov format feel free smoke  \n",
       "1                                                                                                                                                                                                                                                                                                                                             aware peerreviewed study minimal methodological flaw know page link cite constitute bias source restrain self become extremely sarcastic  \n",
       "2                                                                                                                                                                                                                                                                                                                                                fine edit personal gain long edit accord basic policies contribute wikipedia hobby people endless number motivations get involve talk  \n",
       "3                                                                                                                                                                                                                                                                                                           add word plan website contact plan plan skeptic site language quote strong offensive people plan cite evidence balance point view little content present wikipedia article  \n",
       "4  list recent change request sarge baldy even though already discuss extensively need minutia cromwell intro article political mean anarchism belief form rulership undesireable abolish need gobbletygook degrees commonality conflict please hide fact proudhon anticommunist proudhon detail go proudhon article anarchist school precede sundry issueoriented sects bullshit misc nonanarchist leftie movements belong anarchism without adjectives i paragraph ancap book censor  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "comment_text            0\n",
       "toxic                   0\n",
       "severe_toxic            0\n",
       "obscene                 0\n",
       "threat                  0\n",
       "insult                  0\n",
       "identity_hate           0\n",
       "clean                   0\n",
       "cleaned_comment_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the dataframe\n",
    "df1 = df.iloc[:,[0,9,2,3,4,5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cleaned_comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2f52adcf5a111cd3</td>\n",
       "      <td>primarily work citations either add update relate format reconcile previous contributions npov bpov format feel free smoke</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>819b3339c747286f</td>\n",
       "      <td>aware peerreviewed study minimal methodological flaw know page link cite constitute bias source restrain self become extremely sarcastic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b66e5fffbd70f8fe</td>\n",
       "      <td>fine edit personal gain long edit accord basic policies contribute wikipedia hobby people endless number motivations get involve talk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fd7f2ec6efe0315d</td>\n",
       "      <td>add word plan website contact plan plan skeptic site language quote strong offensive people plan cite evidence balance point view little content present wikipedia article</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f78b624060552c1a</td>\n",
       "      <td>list recent change request sarge baldy even though already discuss extensively need minutia cromwell intro article political mean anarchism belief form rulership undesireable abolish need gobbletygook degrees commonality conflict please hide fact proudhon anticommunist proudhon detail go proudhon article anarchist school precede sundry issueoriented sects bullshit misc nonanarchist leftie movements belong anarchism without adjectives i paragraph ancap book censor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  \\\n",
       "0  2f52adcf5a111cd3   \n",
       "1  819b3339c747286f   \n",
       "2  b66e5fffbd70f8fe   \n",
       "3  fd7f2ec6efe0315d   \n",
       "4  f78b624060552c1a   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                  cleaned_comment_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                           primarily work citations either add update relate format reconcile previous contributions npov bpov format feel free smoke   \n",
       "1                                                                                                                                                                                                                                                                                                                                             aware peerreviewed study minimal methodological flaw know page link cite constitute bias source restrain self become extremely sarcastic   \n",
       "2                                                                                                                                                                                                                                                                                                                                                fine edit personal gain long edit accord basic policies contribute wikipedia hobby people endless number motivations get involve talk   \n",
       "3                                                                                                                                                                                                                                                                                                           add word plan website contact plan plan skeptic site language quote strong offensive people plan cite evidence balance point view little content present wikipedia article   \n",
       "4  list recent change request sarge baldy even though already discuss extensively need minutia cromwell intro article political mean anarchism belief form rulership undesireable abolish need gobbletygook degrees commonality conflict please hide fact proudhon anticommunist proudhon detail go proudhon article anarchist school precede sundry issueoriented sects bullshit misc nonanarchist leftie movements belong anarchism without adjectives i paragraph ancap book censor   \n",
       "\n",
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0      0             0        0       0       0              0  \n",
       "1      0             0        0       0       0              0  \n",
       "2      0             0        0       0       0              0  \n",
       "3      0             0        0       0       0              0  \n",
       "4      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test set (note that x and y are not separated due to nltk's way of feature selection)\n",
    "train, test = train_test_split(df1, test_size = 0.2, random_state = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cleaned_comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30200</th>\n",
       "      <td>26de3070fdf8f9de</td>\n",
       "      <td>perhaps perhaps che pig</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34498</th>\n",
       "      <td>f19946d1a3097deb</td>\n",
       "      <td>three women elgar life watch min tv documentary elgar present important new information surprise even biographers raise question mind earth article reach fa status without mention least windflower whose existence well know doubt elgar affairs heart central creativity huge influence work repeat article reach present state barely mention central aspect life</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25278</th>\n",
       "      <td>b5bd02e258f0f42f</td>\n",
       "      <td>edit infobox add audio p nks performance live nd annual grammy award release digital download februar source also add album version song release digital download single june source write release infobox january us radio february digital download live nd annual grammy award digital download</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29073</th>\n",
       "      <td>aef5fc6d99e28f6f</td>\n",
       "      <td>weird indeed put four tildes keep come unsigned anyway edit signature think work</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9290</th>\n",
       "      <td>aef41c4a4d12c0f3</td>\n",
       "      <td>contrary recommendation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  \\\n",
       "30200  26de3070fdf8f9de   \n",
       "34498  f19946d1a3097deb   \n",
       "25278  b5bd02e258f0f42f   \n",
       "29073  aef5fc6d99e28f6f   \n",
       "9290   aef41c4a4d12c0f3   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                        cleaned_comment_text  \\\n",
       "30200                                                                                                                                                                                                                                                                                                                                                perhaps perhaps che pig   \n",
       "34498  three women elgar life watch min tv documentary elgar present important new information surprise even biographers raise question mind earth article reach fa status without mention least windflower whose existence well know doubt elgar affairs heart central creativity huge influence work repeat article reach present state barely mention central aspect life   \n",
       "25278                                                                     edit infobox add audio p nks performance live nd annual grammy award release digital download februar source also add album version song release digital download single june source write release infobox january us radio february digital download live nd annual grammy award digital download   \n",
       "29073                                                                                                                                                                                                                                                                                       weird indeed put four tildes keep come unsigned anyway edit signature think work   \n",
       "9290                                                                                                                                                                                                                                                                                                                                                 contrary recommendation   \n",
       "\n",
       "       toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "30200      1             0        0       0       1              0  \n",
       "34498      0             0        0       0       0              0  \n",
       "25278      0             0        0       0       0              0  \n",
       "29073      0             0        0       0       0              0  \n",
       "9290       0             0        0       0       0              0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cleaned_comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15420</th>\n",
       "      <td>2cbd8b508cc7c2ac</td>\n",
       "      <td>look good change source talk theme musical style specify kissoff anthem indeed true judge lyric write good talk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19180</th>\n",
       "      <td>0f03dd668d7fc2f0</td>\n",
       "      <td>really dog photo dog steal post page nastered priyadarshivishal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46897</th>\n",
       "      <td>f5e25d1b15a9dbf4</td>\n",
       "      <td>listen children night music make</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>18772a6a840177fb</td>\n",
       "      <td>thank thank redirect link idk already page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23094</th>\n",
       "      <td>743f63f120b08059</td>\n",
       "      <td>tribe war muslims</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  \\\n",
       "15420  2cbd8b508cc7c2ac   \n",
       "19180  0f03dd668d7fc2f0   \n",
       "46897  f5e25d1b15a9dbf4   \n",
       "4110   18772a6a840177fb   \n",
       "23094  743f63f120b08059   \n",
       "\n",
       "                                                                                                  cleaned_comment_text  \\\n",
       "15420  look good change source talk theme musical style specify kissoff anthem indeed true judge lyric write good talk   \n",
       "19180                                                  really dog photo dog steal post page nastered priyadarshivishal   \n",
       "46897                                                                                 listen children night music make   \n",
       "4110                                                                        thank thank redirect link idk already page   \n",
       "23094                                                                                                tribe war muslims   \n",
       "\n",
       "       toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "15420      0             0        0       0       0              0  \n",
       "19180      1             0        0       0       1              0  \n",
       "46897      0             0        0       0       0              0  \n",
       "4110       0             0        0       0       0              0  \n",
       "23094      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label_features(df, label, flag, topwords):\n",
    "    \n",
    "    # extract comments from label==flag (1 or 0)\n",
    "    a = df[df[label]==flag].values.tolist()\n",
    "    \n",
    "    # combine comments into a single list\n",
    "    b = [item[1] for item in a]\n",
    "    \n",
    "    # word tokenize each comment\n",
    "    c = [word_tokenize(i) for i in b]\n",
    "    \n",
    "    # remove additional stopwords and words with 2 characters\n",
    "    stop_list = ['wikipedia', 'wiki']\n",
    "    d = [[w for w in doc if w not in stop_list and len(w)>2] for doc in c]\n",
    "   \n",
    "    # convert nested list into a single list\n",
    "    e = [w for doc in d for w in doc]\n",
    "    \n",
    "    # frequency distribution of words\n",
    "    f = nltk.FreqDist(e)\n",
    "    print(len(f))\n",
    "    \n",
    "    # create word features using only top most common words in all documents\n",
    "    word_features = [item[0] for item in f.most_common(topwords)]\n",
    "    \n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12505\n"
     ]
    }
   ],
   "source": [
    "toxic1 = extract_label_features(train, 'toxic', 1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fuck', 'shit', 'pig', 'nigger', 'gay', 'wanker', 'suck', 'ball', 'like', 'get', 'faggot', 'page', 'edit', 'know', 'block', 'make', 'super', 'buttsecks', 'bullshit', 'say', 'people', 'stupid', 'article', 'talk', 'moron', 'poop', 'huge', 'ass', 'want', 'think', 'one', 'rape', 'stop', 'anal', 'would', 'asshole', 'eat', 'hate', 'cock', 'bollocks', 'ban', 'kill', 'yourselfgo', 'time', 'bitch', 'see', 'keep', 'bunksteve', 'come', 'right', 'even', 'take', 'need', 'person', 'delete', 'use', 'work', 'piece', 'life', 'hell', 'try', 'remove', 'love', 'fack', 'give', 'little', 'fag', 'vomit', 'really', 'look', 'please', 'idiot', 'hey', 'fucker', 'whore', 'tell', 'good', 'god', 'user', 'big', 'call', 'fire', 'post', 'well', 'jdelanoy', 'dont', 'cocksucker', 'penis', 'nice', 'anthony', 'also', 'fat', 'way', 'write', 'drink', 'bradbury', 'still', 'attack', 'cunt', 'mothjer', 'comment', 'nothing', 'back', 'never', 'leave', 'many', 'guy', 'read', 'mean', 'information', 'lick', 'bleachanhero', 'source', 'power', 'live', 'ever', 'change', 'dick', 'care', 'revert', 'anything', 'man', 'add', 'put', 'much', 'someone', 'let', 'real', 'damn', 'find', 'name', 'abuse', 'admins', 'warn', 'word', 'die', 'something', 'day', 'dirty', 'better', 'proof', 'wrong', 'feel', 'understand', 'nipple', 'vandalism', 'every', 'bush', 'unblock', 'world', 'bastard', 'help', 'lie', 'continue', 'retard', 'new', 'could', 'thing', 'thank', 'hope', 'place', 'site', 'personal', 'fact', 'bad', 'admin', 'fart', 'things', 'american', 'mum', 'cuntbag', 'show', 'pathetic', 'seem', 'cheese', 'reason', 'realize', 'fuckin', 'first', 'shut', 'account', 'link', 'since', 'crap', 'around', 'believe', 'another', 'computer', 'maybe', 'head', 'problem', 'troll', 'ask', 'shannon', 'play', 'racist', 'cunts', 'last', 'point', 'without', 'job', 'message', 'history', 'image', 'scum', 'else', 'mother', 'loser', 'sure', 'old', 'fggt', 'dumb', 'report', 'away', 'game', 'bias', 'blank', 'cocksucking', 'latinus', 'anyone', 'editors', 'start', 'actually', 'fuckingabf', 'consider', 'yeah', 'question', 'face', 'two', 'enough', 'war', 'claim', 'years', 'nazi', 'sex', 'state', 'probably', 'fool', 'george', 'black', 'must', 'rvv', 'long', 'bunch', 'bag', 'users', 'san', 'run', 'may', 'waste', 'follow', 'stuff', 'sorry', 'mind', 'hear', 'piss', 'kind', 'shithead', 'sit', 'rule', 'part', 'lol', 'create', 'everyone', 'alone', 'guess', 'matter', 'editor', 'yes', 'chocobos', 'already', 'learn', 'others', 'everything', 'whatever', 'gon', 'yet', 'cant', 'sup', 'diego', 'nate', 'free', 'true', 'jerk', 'insult', 'joke', 'white', 'arrest', 'internet', 'allow', 'respect', 'kid', 'vandalize', 'hellor', 'california', 'list', 'happen', 'watch', 'ignorant', 'thats', 'dude', 'asian', 'chula', 'vista', 'view', 'sick', 'lot', 'issue', 'act', 'prove', 'english', 'facts', 'instead', 'section', 'hello', 'truth', 'seriously', 'sign', 'wow', 'sad', 'always', 'case', 'support', 'full', 'agree', 'nlers', 'website', 'motherfucker', 'stay', 'opinion', 'book', 'bite', 'school', 'check', 'fail', 'suggest', 'ugly', 'fucky', 'discussion', 'deletion', 'term', 'include', 'prick', 'end', 'hand', 'sock', 'boy', 'band', 'address', 'pov', 'supertrll', 'spend', 'ruin', 'anyway', 'dead', 'pussy', 'bully', 'ahead', 'enjoy', 'funny', 'rather', 'cause', 'reference', 'mccain', 'action', 'number', 'bother', 'idiots', 'clearly', 'language', 'next', 'either', 'hard', 'content', 'great', 'deal', 'though', 'picture', 'money', 'youcaltlas', 'nonsense', 'year', 'fun', 'meet', 'son', 'listen', 'quite', 'quit', 'encyclopedia', 'less', 'men', 'completely', 'dare', 'steal', 'deserve', 'discuss', 'correct', 'dog', 'different', 'administrator', 'entire', 'idea', 'clear', 'obviously', 'liar', 'whole', 'friends', 'least', 'parent', 'lose', 'course', 'hit', 'jews', 'serious', 'misterwiki', 'bald', 'self', 'mention', 'accuse', 'move', 'regard', 'note', 'simply', 'pay', 'diff', 'child', 'mouth', 'sexual', 'best', 'nobody', 'march', 'ignore', 'forever', 'expect', 'baby', 'salt', 'sound', 'provide', 'sweet', 'butt', 'however', 'info', 'eye', 'days', 'notice', 'wonder', 'country', 'mistake', 'utc', 'excuse', 'dear', 'contributions', 'answer', 'dipshit', 'douche', 'burn', 'text', 'perhaps', 'side', 'etc', 'false', 'annoy', 'rest', 'fix', 'become', 'disgust', 'line', 'threaten', 'ridiculous', 'phuq', 'knob', 'sort', 'fascists', 'simple', 'order', 'hat', 'night', 'might', 'reliable', 'especially', 'shame', 'decide', 'you', 'cite', 'dickhead', 'human', 'screw', 'hole', 'author', 'group', 'fight', 'bring', 'second', 'far', 'fit', 'bloody', 'policy', 'evil', 'grow', 'control', 'cut', 'important', 'forget', 'evidence', 'attention', 'appear', 'censor', 'death', 'three', 'obvious', 'business', 'harass', 'spell', 'news', 'request', 'explain', 'wikipedians', 'pretty', 'sockpuppet', 'close', 'hide', 'stick', 'response', 'speak', 'sense', 'hist', 'jewish', 'apparently', 'vandal', 'current', 'administrators', 'force', 'suppress', 'laugh', 'girl', 'blow', 'kick', 'example', 'protect', 'subject', 'hahahahahahahahahahahahaha', 'exactly', 'bet', 'cry', 'base', 'wish', 'republican', 'break', 'total', 'soon', 'reply', 'brain', 'interest', 'wtf', 'filter', 'cuz', 'contribute', 'exist', 'poor', 'respond', 'statement', 'threats', 'defend', 'happy', 'useless', 'destroy', 'rude', 'material', 'quote', 'several', 'dust', 'stand', 'hold', 'together', 'homosexual', 'unsigned', 'silly', 'turn', 'pull', 'rap', 'wales', 'behavior', 'fine', 'wan', 'single', 'hitler', 'douchebag', 'complete', 'caltlas', 'password', 'totally', 'ill', 'notify', 'contras', 'reality', 'garbage', 'family', 'throw', 'sake', 'relevant', 'high', 'worry', 'worst', 'send', 'small', 'suppose', 'david', 'anymore', 'goodbye', 'wait', 'retardedyour', 'scrotumjpgsuck', 'uhbsirtubgyihihlkjngkjbnkgjnbkjfgnbknfgjkbnkfjgnbjkfnjbkfnjbkjbnfkjnbkjnbkjnfbfkjbnknlkshubnsutybnisueynboiserubnsiunybiosubnioseubnoitybnosiubnosriutbynsoitubnosiubnsoiubni', 'upon', 'blood', 'haha', 'nigga', 'vagina', 'hahaha', 'half', 'college', 'able', 'home', 'spread', 'mine', 'communist', 'behind', 'homosexuals', 'music', 'bear', 'common', 'cool', 'tag', 'admit', 'oli', 'metal', 'nomination', 'dave', 'public', 'precede', 'freak', 'refer', 'mom', 'type', 'friend', 'woman', 'angry', 'okay', 'win', 'fan', 'jesus', 'assholes', 'shoot', 'welcome', 'concern', 'topic', 'attempt', 'push', 'film', 'drive', 'viva', 'kurt', 'sloppy', 'speech', 'political', 'vandalise', 'hurt', 'drop', 'women', 'unless', 'violate', 'position', 'step', 'kiss', 'except', 'form', 'ago', 'shove', 'house', 'figure', 'belong', 'project', 'hours', 'juicy', 'review', 'jew', 'lovers', 'assume', 'tab', 'alstair', 'nerd', 'confirm', 'beat', 'north', 'truly', 'harassment', 'accept', 'btw', 'notable', 'useful', 'children', 'title', 'jack', 'murder', 'city', 'didnt', 'sir', 'contact', 'bigger', 'character', 'shall', 'serve', 'teach', 'general', 'liberal', 'vote', 'puppet', 'complain', 'front', 'describe', 'earth', 'almost', 'refuse', 'entry', 'advocate', 'months', 'within', 'repeatedly', 'mess', 'along', 'fascist', 'lessheard', 'vanu', 'problems', 'punk', 'random', 'attitude', 'somebody', 'community', 'homo', 'erase', 'begin', 'wife', 'today', 'google', 'horrible', 'otherwise', 'nut', 'finally', 'christ', 'twat', 'youre', 'box', 'dumbass', 'disagree', 'difference', 'fake', 'sucksfrozen', 'mad', 'certain', 'past', 'smart', 'trouble', 'flame', 'urantia', 'nazis', 'worse', 'proud', 'arrogant', 'pant', 'song', 'original', 'final', 'whether', 'indeed', 'due', 'surprise', 'pick', 'therefore', 'john', 'arse', 'logic', 'relate', 'queer', 'miss', 'record', 'fly', 'touch', 'save', 'cum', 'niggers', 'lead', 'terrorist', 'hair', 'absolutely', 'improve', 'wont', 'propaganda', 'appreciate', 'shitty', 'law', 'idiotic', 'proper', 'standards', 'top', 'assad', 'genital', 'wedge', 'none', 'fair', 'choose', 'doubt', 'knowledge', 'worthless', 'stink', 'whoever', 'virgin', 'crazy', 'wipe', 'insert', 'abusive', 'monkey', 'jump', 'huh', 'government', 'area', 'blind', 'bore', 'worth', 'stalk', 'smell', 'king', 'genre', 'across', 'prison', 'recent', 'service', 'plot', 'class', 'repeat', 'lazy', 'template', 'suspect', 'hop', 'cover', 'whats', 'email', 'direct', 'catch', 'wear', 'sell', 'low', 'apply', 'stupidity', 'demand', 'argument', 'arab', 'lack', 'special', 'sandbox', 'valid', 'immature', 'spanish', 'jackass', 'fellow', 'biggest', 'omg', 'chance', 'sentence', 'movie', 'level', 'morons', 'party', 'constantly', 'actual', 'separate', 'accusations', 'straight', 'israel', 'accord', 'format', 'forgive', 'staff', 'castro', 'task', 'ones', 'cult', 'china', 'hot', 'bastards', 'load', 'saw', 'research', 'purpose', 'properly', 'return', 'later', 'despite', 'result', 'losers', 'contribs', 'doesnt', 'scream', 'trust', 'clean', 'favor', 'pedophile', 'open', 'argue', 'certainly', 'rat', 'trip', 'merely', 'access', 'hypocrite', 'violation', 'longer', 'although', 'nation', 'isnt', 'ways', 'study', 'disgrace', 'possible', 'chinese', 'involve', 'perfect', 'cia', 'remember', 'officer', 'confuse', 'publish', 'major', 'factual', 'fill', 'imagine', 'situation', 'lock', 'ignorance', 'constructive', 'buddy', 'npov', 'personally', 'main', 'accurate', 'visit', 'father', 'race', 'copyright', 'citation', 'onto', 'style', 'bye', 'pompous', 'vandals', 'scar', 'paragraph', 'freedom', 'scumbag', 'battle', 'agenda', 'undo', 'team', 'fck', 'bull', 'brown', 'join', 'dicks', 'video', 'petty', 'copy', 'minutes', 'doosh', 'scientific', 'unlike', 'media', 'legitimate', 'turkish', 'suffer', 'pain', 'zionist', 'trash', 'honestly', 'drummer', 'swear', 'blah', 'manual', 'nlersi', 'eppstein', 'bastered', 'award', 'star', 'members', 'korea', 'korean', 'criticism', 'consensus', 'silence', 'basement', 'sleep']\n"
     ]
    }
   ],
   "source": [
    "print(toxic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1897\n"
     ]
    }
   ],
   "source": [
    "severe1 = extract_label_features(train, 'severe_toxic', 1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7877\n"
     ]
    }
   ],
   "source": [
    "obscene1 = extract_label_features(train, 'obscene', 1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952\n"
     ]
    }
   ],
   "source": [
    "threat1 = extract_label_features(train, 'threat', 1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n"
     ]
    }
   ],
   "source": [
    "insult1 = extract_label_features(train, 'insult', 1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2516\n"
     ]
    }
   ],
   "source": [
    "identity1 = extract_label_features(train, 'identity_hate', 1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine word features of all labels\n",
    "word_features = toxic1 + severe1 + obscene1 + threat1 + insult1 + identity1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for feature extraction\n",
    "def document_features(document):\n",
    "    document_words1 = word_tokenize(document)\n",
    "    document_words2 = set(document_words1)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words2)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multilabel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform train features into vectors\n",
    "train1 = train.values.tolist()\n",
    "train2 = [item[1] for item in train1]\n",
    "train_feature = [document_features(i) for i in train2]\n",
    "v = DictVectorizer()\n",
    "train_feature1 = v.fit_transform(train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform test features into vectors\n",
    "test1 = test.values.tolist()\n",
    "test2 = [item[1] for item in test1]\n",
    "test_feature = [document_features(i) for i in test2]\n",
    "test_feature1 = v.transform(test_feature) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_pipeline = Pipeline([('clf', OneVsRestClassifier(MultinomialNB())),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing toxic\n",
      "Test accuracy is 0.9448587127158555\n",
      "\n",
      "Confusion matrix:\n",
      " [[8907  304]\n",
      " [ 258  723]]\n",
      "\n",
      "Clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      9211\n",
      "           1       0.70      0.74      0.72       981\n",
      "\n",
      "    accuracy                           0.94     10192\n",
      "   macro avg       0.84      0.85      0.84     10192\n",
      "weighted avg       0.95      0.94      0.95     10192\n",
      "\n",
      "... Processing severe_toxic\n",
      "Test accuracy is 0.9721350078492935\n",
      "\n",
      "Confusion matrix:\n",
      " [[9841  256]\n",
      " [  28   67]]\n",
      "\n",
      "Clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     10097\n",
      "           1       0.21      0.71      0.32        95\n",
      "\n",
      "    accuracy                           0.97     10192\n",
      "   macro avg       0.60      0.84      0.65     10192\n",
      "weighted avg       0.99      0.97      0.98     10192\n",
      "\n",
      "... Processing obscene\n",
      "Test accuracy is 0.9668367346938775\n",
      "\n",
      "Confusion matrix:\n",
      " [[9406  237]\n",
      " [ 101  448]]\n",
      "\n",
      "Clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      9643\n",
      "           1       0.65      0.82      0.73       549\n",
      "\n",
      "    accuracy                           0.97     10192\n",
      "   macro avg       0.82      0.90      0.85     10192\n",
      "weighted avg       0.97      0.97      0.97     10192\n",
      "\n",
      "... Processing threat\n",
      "Test accuracy is 0.9831240188383046\n",
      "\n",
      "Confusion matrix:\n",
      " [[10007   153]\n",
      " [   19    13]]\n",
      "\n",
      "Clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     10160\n",
      "           1       0.08      0.41      0.13        32\n",
      "\n",
      "    accuracy                           0.98     10192\n",
      "   macro avg       0.54      0.70      0.56     10192\n",
      "weighted avg       1.00      0.98      0.99     10192\n",
      "\n",
      "... Processing insult\n",
      "Test accuracy is 0.9588893249607535\n",
      "\n",
      "Confusion matrix:\n",
      " [[9389  289]\n",
      " [ 130  384]]\n",
      "\n",
      "Clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      9678\n",
      "           1       0.57      0.75      0.65       514\n",
      "\n",
      "    accuracy                           0.96     10192\n",
      "   macro avg       0.78      0.86      0.81     10192\n",
      "weighted avg       0.97      0.96      0.96     10192\n",
      "\n",
      "... Processing identity_hate\n",
      "Test accuracy is 0.9734105180533752\n",
      "\n",
      "Confusion matrix:\n",
      " [[9857  237]\n",
      " [  34   64]]\n",
      "\n",
      "Clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     10094\n",
      "           1       0.21      0.65      0.32        98\n",
      "\n",
      "    accuracy                           0.97     10192\n",
      "   macro avg       0.60      0.81      0.65     10192\n",
      "weighted avg       0.99      0.97      0.98     10192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "for category in categories:\n",
    "    \n",
    "    print('... Processing {}'.format(category))\n",
    "    \n",
    "    # train the model\n",
    "    NB_pipeline.fit(train_feature1, train[category])\n",
    "    \n",
    "    # compute the testing accuracy\n",
    "    y_pred = NB_pipeline.predict(test_feature1)\n",
    "    \n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], y_pred)))\n",
    "    print('\\nConfusion matrix:\\n', confusion_matrix(test[category], y_pred))\n",
    "    print('\\nClasification report:\\n', classification_report(test[category], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_pipeline = Pipeline([('clf', OneVsRestClassifier(MultinomialNB())),])\n",
    "\n",
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# train the model\n",
    "multilabel_pipeline.fit(train_feature1, train[categories])\n",
    "\n",
    "# compute the testing accuracy\n",
    "y_pred = multilabel_pipeline.predict(test_feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10192, 1103)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10192, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_labels = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15420</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19180</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46897</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23094</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10664</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31309</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29287</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15328</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40901</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10192 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "15420      0             0        0       0       0              0\n",
       "19180      1             0        0       0       1              0\n",
       "46897      0             0        0       0       0              0\n",
       "4110       0             0        0       0       0              0\n",
       "23094      0             0        0       0       0              0\n",
       "...      ...           ...      ...     ...     ...            ...\n",
       "10664      0             0        0       0       0              0\n",
       "31309      1             0        1       0       1              0\n",
       "29287      0             0        0       0       0              0\n",
       "15328      0             0        0       0       0              0\n",
       "40901      1             0        1       0       0              0\n",
       "\n",
       "[10192 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[:,2:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[:,2:8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test.iloc[:,2:8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10192, 6)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8907   304]\n",
      "  [  258   723]]\n",
      "\n",
      " [[ 9841   256]\n",
      "  [   28    67]]\n",
      "\n",
      " [[ 9406   237]\n",
      "  [  101   448]]\n",
      "\n",
      " [[10007   153]\n",
      "  [   19    13]]\n",
      "\n",
      " [[ 9389   289]\n",
      "  [  130   384]]\n",
      "\n",
      " [[ 9857   237]\n",
      "  [   34    64]]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "mcm = multilabel_confusion_matrix(y_true, y_pred)\n",
    "print(mcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[723, 67, 448, 13, 384, 64]\n",
      "[304, 256, 237, 153, 289, 237]\n",
      "[258, 28, 101, 19, 130, 34]\n",
      "[8907, 9841, 9406, 10007, 9389, 9857]\n"
     ]
    }
   ],
   "source": [
    "# TP, FP, FN, TN\n",
    "\n",
    "TP = list()\n",
    "FP = list()\n",
    "FN = list()\n",
    "TN = list()\n",
    "\n",
    "for i in range(no_of_labels):\n",
    "    TN_i = mcm[i][0][0]\n",
    "    FP_i = mcm[i][0][1]\n",
    "    FN_i = mcm[i][1][0]\n",
    "    TP_i = mcm[i][1][1]\n",
    "    \n",
    "    TP.append(TP_i)\n",
    "    FP.append(FP_i)\n",
    "    FN.append(FN_i)\n",
    "    TN.append(TN_i)\n",
    "    \n",
    "print(TP)\n",
    "print(FP)\n",
    "print(FN)\n",
    "print(TN)\n",
    "\n",
    "# e.g. TP for label 0 ==> TP[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9448587127158555, 0.9721350078492935, 0.9668367346938775, 0.9831240188383046, 0.9588893249607535, 0.9734105180533752]\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "\n",
    "accuracy = list()\n",
    "for i in range(no_of_labels):\n",
    "    accuracy_i = (TP[i] + TN[i]) / (TP[i] + FP[i] + FN[i] + TN[i])\n",
    "    accuracy.append(accuracy_i)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7039922103213242, 0.20743034055727555, 0.654014598540146, 0.0783132530120482, 0.5705794947994056, 0.21262458471760798]\n",
      "[0.7370030581039755, 0.7052631578947368, 0.8160291438979964, 0.40625, 0.7470817120622568, 0.6530612244897959]\n",
      "[0.7201195219123505, 0.3205741626794259, 0.726094003241491, 0.13131313131313133, 0.6470092670598147, 0.32080200501253137]\n"
     ]
    }
   ],
   "source": [
    "# precision, recall, f1 score\n",
    "\n",
    "precision = list()\n",
    "recall = list()\n",
    "f1_score = list()\n",
    "\n",
    "for i in range(no_of_labels):\n",
    "    precision_i = (TP[i]) / ((TP[i] + FP[i]) or not (TP[i] + FP[i]))\n",
    "    precision.append(precision_i)\n",
    "    \n",
    "    recall_i = (TP[i]) / ((TP[i] + FN[i]) or not (TP[i] + FN[i]))\n",
    "    recall.append(recall_i)\n",
    "    \n",
    "    f1_score_i = (2 * precision_i * recall_i) / ((precision_i + recall_i) or not (precision_i + recall_i))\n",
    "    f1_score.append(f1_score_i)\n",
    "    \n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9665423861852434\n"
     ]
    }
   ],
   "source": [
    "# average accuracy\n",
    "\n",
    "avg_accuracy = sum(accuracy) / no_of_labels\n",
    "print(avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5351181102362205\n",
      "0.748788012340238\n",
      "0.6241734019103601\n"
     ]
    }
   ],
   "source": [
    "# micro averaging\n",
    "\n",
    "micro_precision = sum(TP) / (sum(TP) + sum(FP))\n",
    "micro_recall = sum(TP) / (sum(TP) + sum(FN))\n",
    "micro_f1_score = (2 * micro_precision * micro_recall) / (micro_precision + micro_recall)\n",
    "\n",
    "print(micro_precision)\n",
    "print(micro_recall)\n",
    "print(micro_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
