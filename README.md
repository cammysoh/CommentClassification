# Toxic Comment Classification Using Machine Learning and Neural Network
Author: Soh Hui Shan Cammy, cammysoh@gmail.com (link to linkedIn or github resume)

## Objective
The objective of our project is to build a multi-label classification model that can accurately detect different types of toxicity for each comment. There are 6 classes of toxicity - Toxic, Severe Toxic, Obscene, Threat, Insult and Identity Hate.

We would like to observe if complex approaches of word embeddings coupled with deep learning pose any significant improvement in accuracy over simpler approaches. 

For Feature Engineering, we have created word-level features using vectorization methods such as Bag-of-Words, TF-IDF representations, and GloVe word embeddings. 

We have deployed a range of classification methods, from simpler classification methods like Naïve Bayes, Logistic Regression, SVM, to more complex methods such as Neural Networks and CNN.

Data is available from *[Kaggle Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data)*.

## Approach
### Initial Approach and Challenges
Our initial approach is to classify the comments into 6 labels. 

We built three models and each of them has a high average accuracy of 96%. However, the micro-recall and micro-F1-score is very low for embeddings with logistic regression and neural network model.



## Presentation and Report 
Project presentation slide deck can be viewed [here](https://www.slideshare.net/CammySoh/toxic-comment-classification-using-neural-network-and-machine-learning "AML Project Presentation").

A detailed project report can be viewed [here](https://github.com/cammysoh/Toxic-Comment-Classifier/blob/master/Applied%20Machine%20Learning_Project%20Report.pdf "AML Project Report").

## Contributors
(add link to linkedIn account) 
Ayushi Jaiswal, Milouni Desai, Teo Yaling, Soh Hui Shan
